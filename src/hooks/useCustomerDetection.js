import { useEffect, useRef, useState } from 'react';

// face-api.jsë¥¼ ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ ë¡œë“œ
let faceApiPromise = null;
let faceApiModule = null;

async function loadFaceApi() {
  if (faceApiModule) return faceApiModule;
  if (faceApiPromise) return faceApiPromise;
  
  faceApiPromise = import('face-api.js').then(module => {
    faceApiModule = module;
    return module;
  });
  
  return faceApiPromise;
}

/**
 * ì›¹ìº ìœ¼ë¡œ ê³ ê° ê°ì§€í•˜ëŠ” í›…
 * face-api.js ì‚¬ìš©
 */
export function useCustomerDetection(onCustomerDetected, enabled = true) {
  const videoRef = useRef(null);
  const [isLoaded, setIsLoaded] = useState(false);
  const [isDetecting, setIsDetecting] = useState(false);
  const [detectionProgress, setDetectionProgress] = useState(0); // 0-100
  const detectionTimeoutRef = useRef(null);
  const lastDetectionTimeRef = useRef(0);
  const hasCalledCallbackRef = useRef(false); // ì½œë°± í˜¸ì¶œ ì—¬ë¶€ ì¶”ì 
  const onCustomerDetectedRef = useRef(onCustomerDetected); // refë¡œ ì €ì¥
  const isDetectingRef = useRef(false); // ë™ê¸°ì  ê°ì§€ ìƒíƒœ ì¶”ì 
  
  // ì½œë°± ì—…ë°ì´íŠ¸
  useEffect(() => {
    onCustomerDetectedRef.current = onCustomerDetected;
  }, [onCustomerDetected]);

  useEffect(() => {
    if (!enabled) {
      console.log('[ì–¼êµ´ê°ì§€] ë¹„í™œì„±í™”ë¨ (enabled=false)');
      return;
    }
    
    console.log('[ì–¼êµ´ê°ì§€] í™œì„±í™”ë¨ (enabled=true)');

    let mounted = true;
    let stream = null;
    
    // enabledê°€ ë³€ê²½ë˜ë©´ ë¦¬ì…‹
    hasCalledCallbackRef.current = false;
    isDetectingRef.current = false;

    async function loadModels() {
      try {
        console.log('[ì–¼êµ´ê°ì§€] face-api.js ëª¨ë¸ ë¡œë“œ ì‹œì‘...');
        
        // face-api.js ëª¨ë“ˆ ë¡œë“œ (ì „ì—­ìœ¼ë¡œ í•œ ë²ˆë§Œ)
        const faceapi = await loadFaceApi();
        
        // ëª¨ë¸ íŒŒì¼ ë¡œë“œ
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
          faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
        ]);

        console.log('[ì–¼êµ´ê°ì§€] âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!');
        if (mounted) {
          setIsLoaded(true);
        }
      } catch (error) {
        console.error('[ì–¼êµ´ê°ì§€] âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
      }
    }

    async function startWebcam() {
      try {
        console.log('[ì–¼êµ´ê°ì§€] ì›¹ìº  ì‹œì‘ ì¤‘...');
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: 640,
            height: 480,
          },
        });

        if (videoRef.current && mounted) {
          videoRef.current.srcObject = stream;
          await videoRef.current.play();
          console.log('[ì–¼êµ´ê°ì§€] âœ… ì›¹ìº  ì‹œì‘ ì™„ë£Œ!');
        }
      } catch (error) {
        console.error('[ì–¼êµ´ê°ì§€] âŒ ì›¹ìº  ì‹œì‘ ì‹¤íŒ¨:', error);
      }
    }

    loadModels();
    startWebcam();

    return () => {
      mounted = false;
      if (stream) {
        stream.getTracks().forEach(track => track.stop());
      }
      if (detectionTimeoutRef.current) {
        clearTimeout(detectionTimeoutRef.current);
      }
    };
  }, [enabled]);

  useEffect(() => {
    if (!isLoaded || !enabled || !videoRef.current) {
      console.log('ê°ì§€ ì‹œì‘ ì•ˆë¨:', { isLoaded, enabled, hasVideo: !!videoRef.current });
      return;
    }

    let mounted = true;
    let animationId = null;

    async function detectFace() {
      if (!mounted || !videoRef.current) return;

      // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
      if (videoRef.current.readyState < 2) {
        animationId = requestAnimationFrame(detectFace);
        return;
      }

      try {
        // ì´ë¯¸ ë¡œë“œëœ ëª¨ë“ˆ ì‚¬ìš©
        if (!faceApiModule) return;
        
        const detections = await faceApiModule
          .detectAllFaces(
            videoRef.current,
            new faceApiModule.TinyFaceDetectorOptions()
          )
          .withFaceLandmarks();

        const now = Date.now();

        if (detections.length > 0) {
          // console.log(`[ì–¼êµ´ê°ì§€] ì–¼êµ´ ${detections.length}ê°œ ê°ì§€ë¨`);
          
          // ì–¼êµ´ì´ ê°ì§€ë¨ (ref ì‚¬ìš©ìœ¼ë¡œ ë™ê¸°ì  ì²´í¬)
          if (!isDetectingRef.current) {
            console.log('[ì–¼êµ´ê°ì§€] âœ… ê°ì§€ ì‹œì‘! í”„ë¡œê·¸ë ˆìŠ¤ ì‹œì‘');
            isDetectingRef.current = true;
            setIsDetecting(true);
            lastDetectionTimeRef.current = now;
            hasCalledCallbackRef.current = false; // ë¦¬ì…‹
          }

          // ê²½ê³¼ ì‹œê°„ ê³„ì‚° ë° í”„ë¡œê·¸ë ˆìŠ¤ ì—…ë°ì´íŠ¸
          const elapsed = now - lastDetectionTimeRef.current;
          const progress = Math.min((elapsed / 1000) * 100, 100);
          setDetectionProgress(progress);
          
          // 1ì´ˆ ì™„ë£Œ (100%) ì‹œ ì½œë°± í˜¸ì¶œ
          if (progress >= 100 && !hasCalledCallbackRef.current) {
            console.log('[ì–¼êµ´ê°ì§€] ğŸ‰ ì¸ì‹ ì™„ë£Œ (100%)! ì£¼ë¬¸ ì‹œì‘');
            console.log('[ì–¼êµ´ê°ì§€] âš ï¸ ì£¼ì˜: TTS ê¶Œí•œì´ ì—†ìœ¼ë©´ ì†Œë¦¬ê°€ ì•ˆ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
            console.log('[ì–¼êµ´ê°ì§€] ğŸ’¡ í•´ê²°: í™”ë©´ì„ ë¨¼ì € í´ë¦­í•´ì£¼ì„¸ìš”!');
            hasCalledCallbackRef.current = true; // ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
            
            if (onCustomerDetectedRef.current) {
              onCustomerDetectedRef.current();
            }
          }
        } else {
          // ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ
          if (isDetectingRef.current) {
            console.log('[ì–¼êµ´ê°ì§€] ê°ì§€ ì¢…ë£Œ (ì–¼êµ´ ì‚¬ë¼ì§)');
            isDetectingRef.current = false;
            setIsDetecting(false);
            setDetectionProgress(0); // í”„ë¡œê·¸ë ˆìŠ¤ ë¦¬ì…‹
            hasCalledCallbackRef.current = false; // ë¦¬ì…‹
          }
        }
      } catch (error) {
        console.error('Face detection ì—ëŸ¬:', error);
      }

      // ë‹¤ìŒ í”„ë ˆì„ ê°ì§€
      animationId = requestAnimationFrame(detectFace);
    }

    console.log('[ì–¼êµ´ê°ì§€] ì–¼êµ´ ê°ì§€ ë£¨í”„ ì‹œì‘');
    detectFace();

    return () => {
      mounted = false;
      if (animationId) {
        cancelAnimationFrame(animationId);
      }
    };
  }, [isLoaded, enabled]); // onCustomerDetectedì™€ isDetecting ì œê±°!

  // enabledê°€ falseê°€ ë˜ë©´ (ì£¼ë¬¸ ì‹œì‘) í”„ë¡œê·¸ë ˆìŠ¤ ë¦¬ì…‹
  useEffect(() => {
    if (!enabled) {
      setDetectionProgress(0);
      isDetectingRef.current = false;
      setIsDetecting(false);
    }
  }, [enabled]);

  return {
    videoRef,
    isLoaded,
    isDetecting,
    detectionProgress, // 0-100
  };
}

export default useCustomerDetection;

