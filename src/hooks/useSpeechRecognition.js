import { useEffect, useRef, useState, useCallback } from 'react';

/**
 * ìŒì„± ì¸ì‹ í›…
 * Web Speech API ì‚¬ìš©
 */
export function useSpeechRecognition(onResult, enabled = false, language = 'ko') {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');
  const recognitionRef = useRef(null);
  const silenceTimerRef = useRef(null);
  const enabledRef = useRef(enabled); // refë¡œ ê´€ë¦¬
  const languageRef = useRef(language); // refë¡œ ê´€ë¦¬
  const isManuallyStoppedRef = useRef(false); // ìˆ˜ë™ ì¤‘ì§€ í”Œë˜ê·¸
  
  // enabled ì—…ë°ì´íŠ¸
  useEffect(() => {
    enabledRef.current = enabled;
  }, [enabled]);
  
  // language ì—…ë°ì´íŠ¸
  useEffect(() => {
    languageRef.current = language;
  }, [language]);

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  useEffect(() => {
    if (typeof window === 'undefined') return;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      console.error('Speech Recognition not supported');
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    // ì–¸ì–´ ì„¤ì •ì€ start ì‹œì ì— ë™ì ìœ¼ë¡œ ë³€ê²½
    recognition.lang = language === 'en' ? 'en-US' : 'ko-KR';
    recognition.maxAlternatives = 1;
    
    console.log('[ìŒì„±ì¸ì‹] ì´ˆê¸° ì–¸ì–´ ì„¤ì •:', recognition.lang);

    recognition.onstart = () => {
      console.log('[ìŒì„±ì¸ì‹] âœ… ì‹œì‘');
      setIsListening(true);
      isManuallyStoppedRef.current = false;
    };

    recognition.onend = () => {
      console.log('[ìŒì„±ì¸ì‹] ì¢…ë£Œ');
      setIsListening(false);
      
      // ìˆ˜ë™ ì¤‘ì§€ê°€ ì•„ë‹ˆê³ , enabled ìƒíƒœë©´ ìë™ ì¬ì‹œì‘
      if (!isManuallyStoppedRef.current && enabledRef.current) {
        console.log('[ìŒì„±ì¸ì‹] ìë™ ì¬ì‹œì‘ ì‹œë„ (500ms í›„)...');
        setTimeout(() => {
          if (enabledRef.current && !isManuallyStoppedRef.current) {
            try {
              recognition.start();
              console.log('[ìŒì„±ì¸ì‹] âœ… ì¬ì‹œì‘ ì„±ê³µ');
            } catch (error) {
              if (error.message.includes('already started')) {
                console.log('[ìŒì„±ì¸ì‹] ì´ë¯¸ ì‹œì‘ë¨');
              } else {
                console.log('[ìŒì„±ì¸ì‹] ì¬ì‹œì‘ ì‹¤íŒ¨:', error.message);
              }
            }
          }
        }, 500); // ì¶©ë¶„í•œ ì§€ì—°
      } else {
        console.log('[ìŒì„±ì¸ì‹] ì¬ì‹œì‘ ì•ˆ í•¨ (enabled:', enabledRef.current, ', stopped:', isManuallyStoppedRef.current, ')');
      }
    };

    recognition.onerror = (event) => {
      console.error('[ìŒì„±ì¸ì‹] âŒ ì—ëŸ¬:', event.error);
      
      // abortedëŠ” ì •ìƒ ì¤‘ì§€ì´ë¯€ë¡œ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ
      if (event.error === 'aborted') {
        console.log('[ìŒì„±ì¸ì‹] ì •ìƒ ì¤‘ì§€ë¨');
        isManuallyStoppedRef.current = true;
        return;
      }
      
      // no-speechëŠ” ìë™ìœ¼ë¡œ ì¬ì‹œì‘ë¨ (onendì—ì„œ ì²˜ë¦¬)
      if (event.error === 'no-speech') {
        console.log('[ìŒì„±ì¸ì‹] ìŒì„± ì—†ìŒ (ìë™ ì¬ì‹œì‘ ëŒ€ê¸°)');
        // isManuallyStoppedRefëŠ” falseë¡œ ìœ ì§€ â†’ onendì—ì„œ ì¬ì‹œì‘ë¨
        return;
      }
      
      // audio-capture ì—ëŸ¬ëŠ” ë³µêµ¬ ì‹œë„
      if (event.error === 'audio-capture') {
        console.log('[ìŒì„±ì¸ì‹] ë§ˆì´í¬ ë¬¸ì œ (ì¬ì‹œì‘ ì‹œë„)');
        return;
      }
      
      // not-allowedëŠ” ê¶Œí•œ ë¬¸ì œ
      if (event.error === 'not-allowed') {
        console.error('[ìŒì„±ì¸ì‹] âš ï¸ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€! í™”ë©´ì„ í´ë¦­í•˜ì„¸ìš”.');
        isManuallyStoppedRef.current = true;
        return;
      }
      
      // ê¸°íƒ€ ì—ëŸ¬ëŠ” ë¡œê·¸ë§Œ
      console.warn('[ìŒì„±ì¸ì‹] ì—ëŸ¬ ë°œìƒ, onendì—ì„œ ì²˜ë¦¬ë¨');
    };

    recognition.onresult = (event) => {
      let interim = '';
      let final = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        const text = result[0].transcript;

        if (result.isFinal) {
          final += text;
        } else {
          interim += text;
        }
      }

      if (interim) {
        console.log('[ìŒì„±ì¸ì‹] ğŸ”¤ ì¤‘ê°„ ê²°ê³¼:', interim);
        setInterimTranscript(interim);
        
        // ì¹¨ë¬µ íƒ€ì´ë¨¸ ë¦¬ì…‹
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
        }
        
        // 1ì´ˆ ì¹¨ë¬µ ê°ì§€
        silenceTimerRef.current = setTimeout(() => {
          if (interim.trim()) {
            // ìµœì¢… ê²°ê³¼ë¡œ ì²˜ë¦¬
            console.log('[ìŒì„±ì¸ì‹] â±ï¸ ì¹¨ë¬µ ê°ì§€ â†’ ìµœì¢… ê²°ê³¼ë¡œ ì²˜ë¦¬:', interim.trim());
            setTranscript(interim.trim());
            setInterimTranscript('');
            
            if (onResult) {
              console.log('[ìŒì„±ì¸ì‹] ğŸ“¤ onResult í˜¸ì¶œ:', interim.trim());
              onResult(interim.trim());
            }
          }
        }, 1000);
      }

      if (final) {
        const finalText = final.trim();
        console.log('[ìŒì„±ì¸ì‹] âœ… ìµœì¢… ê²°ê³¼:', finalText);
        setTranscript(finalText);
        setInterimTranscript('');
        
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
        }
        
        if (onResult && finalText) {
          console.log('[ìŒì„±ì¸ì‹] ğŸ“¤ onResult í˜¸ì¶œ:', finalText);
          onResult(finalText);
        }
      }
    };

    recognitionRef.current = recognition;

    return () => {
      if (recognition) {
        recognition.stop();
      }
      if (silenceTimerRef.current) {
        clearTimeout(silenceTimerRef.current);
      }
    };
  }, [onResult]);

  // enabled ìƒíƒœì— ë”°ë¼ ì‹œì‘/ì¤‘ì§€ (Web Speech API)
  useEffect(() => {
    if (!recognitionRef.current) return;

    if (enabled && !isListening) {
      console.log('[ìŒì„±ì¸ì‹] Web Speech API ì‹œì‘ ì‹œë„...');
      console.log('[ìŒì„±ì¸ì‹] ì–¸ì–´:', languageRef.current);
      isManuallyStoppedRef.current = false;
      
      // ì–¸ì–´ ì„¤ì • ì—…ë°ì´íŠ¸
      const langCode = languageRef.current === 'en' ? 'en-US' : 'ko-KR';
      recognitionRef.current.lang = langCode;
      console.log('[ìŒì„±ì¸ì‹] ì–¸ì–´ ì„¤ì •:', langCode);
      
      // ì•½ê°„ì˜ ì§€ì—°ì„ ë‘ê³  ì‹œì‘ (ì´ë¯¸ ì‹œì‘ëœ ê²½ìš° ë°©ì§€)
      setTimeout(() => {
        if (recognitionRef.current && !isListening && enabledRef.current) {
          try {
            recognitionRef.current.start();
          } catch (error) {
            if (error.message.includes('already started')) {
              console.log('[ìŒì„±ì¸ì‹] ì´ë¯¸ ì‹œì‘ë¨, ë¬´ì‹œ');
            } else {
              console.log('[ìŒì„±ì¸ì‹] ì‹œì‘ ì‹¤íŒ¨:', error.message);
            }
          }
        }
      }, 200);
    } else if (!enabled && isListening) {
      console.log('[ìŒì„±ì¸ì‹] Web Speech API ì¤‘ì§€...');
      isManuallyStoppedRef.current = true;
      recognitionRef.current.stop();
    }
  }, [enabled, isListening]);

  const start = useCallback(() => {
    if (recognitionRef.current && !isListening) {
      try {
        recognitionRef.current.start();
      } catch (error) {
        console.log('ì‹œì‘ ì—ëŸ¬:', error);
      }
    }
  }, [isListening]);

  const stop = useCallback(() => {
    if (recognitionRef.current && isListening) {
      console.log('[ìŒì„±ì¸ì‹] ìˆ˜ë™ ì¤‘ì§€');
      isManuallyStoppedRef.current = true;
      recognitionRef.current.stop();
    }
  }, [isListening]);

  return {
    isListening,
    transcript,
    interimTranscript,
    start,
    stop,
  };
}

export default useSpeechRecognition;

