import { useCallback, useEffect, useRef, useState } from 'react';

/**
 * í•œêµ­ì–´ TTSë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
 * ìžì—°ìŠ¤ëŸ¬ìš´ ë°œìŒì„ ìœ„í•´ ë„ì–´ì“°ê¸°ì™€ ì‰¼í‘œ ì¶”ê°€
 */
function preprocessKoreanText(text) {
  // ìˆ«ìž + ì› ì‚¬ì´ì— ê³µë°± ì¶”ê°€
  text = text.replace(/(\d+)(ì›)/g, '$1 $2');
  
  // "~ìž…ë‹ˆë‹¤"ë¥¼ "~ ìž…ë‹ˆë‹¤"ë¡œ (ì•½ê°„ì˜ ì‰¼)
  text = text.replace(/([ê°€-íž£]+)(ìž…ë‹ˆë‹¤|ì´ì—ìš”|ì˜ˆìš”)/g, '$1 $2');
  
  // "~í•˜ì…¨ìŠµë‹ˆë‹¤"ë¥¼ "~ í•˜ì…¨ìŠµë‹ˆë‹¤"ë¡œ
  text = text.replace(/([ê°€-íž£]+)(í•˜ì…¨ìŠµë‹ˆë‹¤|í•˜ì…¨ì–´ìš”)/g, '$1 $2');
  
  // ê°íƒ„ì‚¬ ë’¤ì— ì‰¼í‘œ ì¶”ê°€ (ì´ë¯¸ ìžˆìœ¼ë©´ íŒ¨ìŠ¤)
  text = text.replace(/([ë„¤ë„µì•„ì˜ˆ])(\s)(?![,!?])/g, '$1, ');
  
  // "~ìš”" ë’¤ì— ì•½ê°„ì˜ ì‰¼ (ë¬¸ìž¥ ì¤‘ê°„ì¼ ë•Œë§Œ)
  text = text.replace(/([ê°€-íž£]+ìš”)\s+([ê°€-íž£])/g, '$1, $2');
  
  return text;
}

/**
 * TTS (Text-to-Speech) í›…
 * Web Speech API ì‚¬ìš©
 */
export function useTextToSpeech(onSpeechEnd) {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [queue, setQueue] = useState([]);
  const [voicesLoaded, setVoicesLoaded] = useState(false);
  const synthRef = useRef(null);

  useEffect(() => {
    if (typeof window !== 'undefined') {
      synthRef.current = window.speechSynthesis;
      
      // ìŒì„± ëª©ë¡ ë¡œë“œ ëŒ€ê¸°
      const loadVoices = () => {
        const voices = synthRef.current.getVoices();
        if (voices.length > 0) {
          console.log('[TTS] ìŒì„± ëª©ë¡ ë¡œë“œ ì™„ë£Œ:', voices.length, 'ê°œ');
          setVoicesLoaded(true);
        }
      };
      
      loadVoices();
      
      if (synthRef.current.onvoiceschanged !== undefined) {
        synthRef.current.onvoiceschanged = loadVoices;
      }
    }
  }, []);

  const speak = useCallback((text, options = {}) => {
    if (!synthRef.current || !text) {
      console.warn('[TTS] speak í˜¸ì¶œ ì‹¤íŒ¨:', { hasSynth: !!synthRef.current, hasText: !!text });
      return;
    }

    console.log('[TTS] ðŸ”Š speak í˜¸ì¶œ:', text);
    console.log('[TTS] ì–¸ì–´:', options.language || 'ko');

    // í˜„ìž¬ ìž¬ìƒ ì¤‘ì¸ ê²ƒ ì·¨ì†Œ
    synthRef.current.cancel();

    // ì–¸ì–´ë³„ ì„¤ì •
    const language = options.language || 'ko';
    const langCode = language === 'en' ? 'en-US' : 'ko-KR';
    
    // í•œêµ­ì–´ì¼ ê²½ìš° í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
    const processedText = language === 'ko' ? preprocessKoreanText(text) : text;
    
    if (processedText !== text) {
      console.log('[TTS] ðŸ“ ì „ì²˜ë¦¬ í›„:', processedText);
    }

    const utterance = new SpeechSynthesisUtterance(processedText);
    
    utterance.lang = langCode;
    // í•œêµ­ì–´ëŠ” ì•½ê°„ ëŠë¦¬ê²Œ, ì˜ì–´ëŠ” ê¸°ë³¸ ì†ë„
    utterance.rate = options.rate || (language === 'ko' ? 0.9 : 1.0);
    // í•œêµ­ì–´ëŠ” ì•½ê°„ ë†’ì€ í†¤ìœ¼ë¡œ (ë” ì¹œê·¼í•˜ê²Œ)
    utterance.pitch = options.pitch || (language === 'ko' ? 1.1 : 1.0);
    utterance.volume = options.volume || 1.0;

    // í•´ë‹¹ ì–¸ì–´ì˜ ìŒì„± ì°¾ê¸°
    const voices = synthRef.current.getVoices();
    console.log('[TTS] ðŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡:');
    voices.forEach((voice, idx) => {
      console.log(`  ${idx + 1}. ${voice.name} (${voice.lang}) ${voice.default ? 'â­ ê¸°ë³¸' : ''}`);
    });
    
    // ì–¸ì–´ë³„ë¡œ ìµœì ì˜ ìŒì„± ì°¾ê¸°
    let selectedVoice;
    if (language === 'en') {
      // ì˜ì–´ ìŒì„± ìš°ì„ ìˆœìœ„: en-US > en-GB > en-*
      selectedVoice = voices.find(voice => voice.lang === 'en-US') ||
                      voices.find(voice => voice.lang === 'en-GB') ||
                      voices.find(voice => voice.lang.startsWith('en'));
      
      if (selectedVoice) {
        console.log('[TTS] âœ… ì˜ì–´ ìŒì„± ì„ íƒ:', selectedVoice.name, '(', selectedVoice.lang, ')');
        utterance.voice = selectedVoice;
      } else {
        console.warn('[TTS] âš ï¸ ì˜ì–´ ìŒì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„± ì‚¬ìš©');
      }
    } else {
      // í•œêµ­ì–´ ìŒì„±
      selectedVoice = voices.find(voice => voice.lang.startsWith('ko'));
      
      if (selectedVoice) {
        console.log('[TTS] âœ… í•œêµ­ì–´ ìŒì„± ì„ íƒ:', selectedVoice.name, '(', selectedVoice.lang, ')');
        utterance.voice = selectedVoice;
      } else {
        console.warn('[TTS] âš ï¸ í•œêµ­ì–´ ìŒì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„± ì‚¬ìš©');
        console.log('[TTS] ðŸ’¡ ì‹œìŠ¤í…œ ì„¤ì •ì—ì„œ í•œêµ­ì–´ TTSë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”');
      }
    }

    utterance.onstart = () => {
      console.log('[TTS] âœ… ì‹œìž‘:', text);
      console.log('[TTS] ðŸŽµ ì†Œë¦¬ê°€ ë“¤ë¦¬ì§€ ì•Šìœ¼ë©´ ì‹œìŠ¤í…œ ë³¼ë¥¨ê³¼ ë¸Œë¼ìš°ì € íƒ­ ìŒì†Œê±° ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”');
      setIsSpeaking(true);
    };

    utterance.onend = () => {
      console.log('[TTS] âœ… ì¢…ë£Œ');
      setIsSpeaking(false);
      
      if (onSpeechEnd) {
        onSpeechEnd();
      }
    };

    utterance.onerror = (event) => {
      console.error('[TTS] âŒ ì—ëŸ¬:', event.error, event);
      console.log('[TTS] ì—ëŸ¬ ìƒì„¸:', {
        type: event.type,
        error: event.error,
        charIndex: event.charIndex,
        elapsedTime: event.elapsedTime
      });
      setIsSpeaking(false);
    };

    utterance.onpause = () => {
      console.log('[TTS] â¸ï¸ ì¼ì‹œì •ì§€');
    };

    utterance.onresume = () => {
      console.log('[TTS] â–¶ï¸ ìž¬ê°œ');
    };

    utterance.onboundary = (event) => {
      // ë‹¨ì–´/ë¬¸ìž¥ ê²½ê³„ ì´ë²¤íŠ¸ (ë„ˆë¬´ ë§Žì´ ì¶œë ¥ë˜ë¯€ë¡œ ì£¼ì„)
      // console.log('[TTS] ðŸ”¤ ê²½ê³„:', event.name, 'at', event.charIndex);
    };

    console.log('[TTS] ðŸ“¤ utterance ì„¤ì •:', {
      text: text.substring(0, 50) + (text.length > 50 ? '...' : ''),
      lang: utterance.lang,
      rate: utterance.rate,
      pitch: utterance.pitch,
      volume: utterance.volume,
      voice: utterance.voice?.name || 'ê¸°ë³¸'
    });
    
    console.log('[TTS] ðŸŽ™ï¸ speechSynthesis.speak() ì‹¤í–‰...');
    synthRef.current.speak(utterance);
    
    // ìƒíƒœ í™•ì¸
    setTimeout(() => {
      console.log('[TTS] ðŸ“Š ìƒíƒœ ì²´í¬:', {
        speaking: synthRef.current.speaking,
        pending: synthRef.current.pending,
        paused: synthRef.current.paused
      });
    }, 100);
  }, [onSpeechEnd]);

  const cancel = useCallback(() => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(false);
    }
  }, []);

  const pause = useCallback(() => {
    if (synthRef.current) {
      synthRef.current.pause();
    }
  }, []);

  const resume = useCallback(() => {
    if (synthRef.current) {
      synthRef.current.resume();
    }
  }, []);

  return {
    speak,
    cancel,
    pause,
    resume,
    isSpeaking,
  };
}

export default useTextToSpeech;

